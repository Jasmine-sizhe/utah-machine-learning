{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Decision Tree\")\n",
    "from DecisionTree import ID3\n",
    "\n",
    "class BaggedTrees:\n",
    "    def __init__(self, n_trees):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, data, attributes):\n",
    "        for _ in range(self.n_trees):\n",
    "            # 1. Sample with replacement from data\n",
    "            bootstrap_sample = data.sample(n=len(data), replace=True)\n",
    "            \n",
    "            # 2. Train a decision tree on this sample\n",
    "            tree = ID3(bootstrap_sample, attributes, float('inf'))\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict_tree(self, tree, instance):\n",
    "        node = tree\n",
    "        while node.children: \n",
    "            attribute_name = node.attributes \n",
    "            attribute_value = instance[attribute_name]\n",
    "            matched_child = None\n",
    "            for child in node.children:\n",
    "                if child.attributes == attribute_value:  \n",
    "                    matched_child = child  \n",
    "                    break\n",
    "            if matched_child:\n",
    "                node = matched_child\n",
    "                for subnode in node.children:\n",
    "                    node = subnode\n",
    "            else:\n",
    "                break\n",
    "        return node.label\n",
    "\n",
    "    def predict(self, dataset):\n",
    "        all_predictions = []\n",
    "\n",
    "        # For each instance in the dataset\n",
    "        for _, instance in dataset.iterrows():\n",
    "            # Predict with each tree and vote\n",
    "            predictions = [self.predict_tree(tree, instance) for tree in self.trees]\n",
    "            # Append the majority vote to all_predictions\n",
    "            all_predictions.append(max(set(predictions), key=predictions.count))\n",
    "\n",
    "        return all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for real data set\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert continuous attributes to binary\n",
    "    for column in ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']:\n",
    "        median = df[column].median()\n",
    "        df[column] = df[column].apply(lambda x: 1 if x > median else 0)\n",
    "    \n",
    "    # Note: For columns with \"unknown\", we'll leave them as is. Pandas will treat them as a separate category.\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_bank_data():\n",
    "    # Load the training and test data\n",
    "    test_file_path = \"Data/bank-4/test.csv\"\n",
    "    train_file_path = \"Data/bank-4/train.csv\"\n",
    "    column_names = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
    "    \n",
    "    df_bank_train = pd.read_csv(train_file_path, names=column_names)\n",
    "    df_bank_test = pd.read_csv(test_file_path, names=column_names)\n",
    "    bank_attributes = df_bank_train.columns.tolist()[:-1]\n",
    "\n",
    "    # Apply preprocessing to train and test datasets (assuming you have already defined preprocess_data)\n",
    "    train_data = preprocess_data(df_bank_train)\n",
    "    test_data = preprocess_data(df_bank_test)\n",
    "    attributes = bank_attributes\n",
    "\n",
    "    return train_data, test_data, attributes\n",
    "\n",
    "# # Load the training and test data\n",
    "# test_file_path = \"Data/bank-4/test.csv\"\n",
    "# train_file_path = \"Data/bank-4/train.csv\"\n",
    "# column_names = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
    "# df_bank_train = pd.read_csv(train_file_path, names=column_names)\n",
    "# df_bank_test = pd.read_csv(test_file_path, names=column_names)\n",
    "# bank_attributes = df_bank_train.columns.tolist()[:-1]\n",
    "\n",
    "# # Apply preprocessing to train and test datasets\n",
    "# train_data = preprocess_data(df_bank_train)\n",
    "# test_data = preprocess_data(df_bank_test)\n",
    "# attributes = bank_attributes\n",
    "\n",
    "train_data, test_data, attributes = load_bank_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\Bagging_bank.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m11\u001b[39m):  \u001b[39m# Looping n from 1 to 500\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     bagged_model \u001b[39m=\u001b[39m BaggedTrees(n_trees\u001b[39m=\u001b[39mn)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     bagged_model\u001b[39m.\u001b[39;49mfit(train_data, attributes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Training error\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     predictions \u001b[39m=\u001b[39m bagged_model\u001b[39m.\u001b[39mpredict(train_data)\n",
      "\u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\Bagging_bank.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m bootstrap_sample \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msample(n\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data), replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# 2. Train a decision tree on this sample\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m tree \u001b[39m=\u001b[39m ID3(bootstrap_sample, attributes, \u001b[39mfloat\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39minf\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1462352/OneDrive%20-%20University%20of%20Utah/Desktop/git/utah-machine-learning/Ensemble%20Learning/Bagging_bank.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "File \u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\DecisionTree.py:176\u001b[0m, in \u001b[0;36mID3\u001b[1;34m(S, Attributes, max_depth, feature_subset_size, purity_measurement, root)\u001b[0m\n\u001b[0;32m    174\u001b[0m             child_node\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m most_common_label\n\u001b[0;32m    175\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m             ID3(Sv, remaining_attributes, max_depth\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, feature_subset_size, purity_measurement, root\u001b[39m=\u001b[39;49mchild_node)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m root\n",
      "File \u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\DecisionTree.py:176\u001b[0m, in \u001b[0;36mID3\u001b[1;34m(S, Attributes, max_depth, feature_subset_size, purity_measurement, root)\u001b[0m\n\u001b[0;32m    174\u001b[0m             child_node\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m most_common_label\n\u001b[0;32m    175\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m             ID3(Sv, remaining_attributes, max_depth\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, feature_subset_size, purity_measurement, root\u001b[39m=\u001b[39;49mchild_node)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m root\n",
      "    \u001b[1;31m[... skipping similar frames: ID3 at line 176 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\DecisionTree.py:176\u001b[0m, in \u001b[0;36mID3\u001b[1;34m(S, Attributes, max_depth, feature_subset_size, purity_measurement, root)\u001b[0m\n\u001b[0;32m    174\u001b[0m             child_node\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m most_common_label\n\u001b[0;32m    175\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m             ID3(Sv, remaining_attributes, max_depth\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, feature_subset_size, purity_measurement, root\u001b[39m=\u001b[39;49mchild_node)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m root\n",
      "File \u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\DecisionTree.py:148\u001b[0m, in \u001b[0;36mID3\u001b[1;34m(S, Attributes, max_depth, feature_subset_size, purity_measurement, root)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m# Randomly select a subset of features for splitting\u001b[39;00m\n\u001b[0;32m    147\u001b[0m selected_features \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(Attributes, \u001b[39mmin\u001b[39m(feature_subset_size, \u001b[39mlen\u001b[39m(Attributes)))\n\u001b[1;32m--> 148\u001b[0m best_attribute \u001b[39m=\u001b[39m find_best_attribute(S, selected_features, class_list, purity_measurement)\n\u001b[0;32m    150\u001b[0m \u001b[39m# Choose the best attribute A to split S\u001b[39;00m\n\u001b[0;32m    151\u001b[0m best_attribute \u001b[39m=\u001b[39m find_best_attribute(S, Attributes, class_list, purity_measurement)\n",
      "File \u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\DecisionTree.py:87\u001b[0m, in \u001b[0;36mfind_best_attribute\u001b[1;34m(data, attributes, class_list, purity_measurement)\u001b[0m\n\u001b[0;32m     84\u001b[0m max_info_feature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39mfor\u001b[39;00m attribute \u001b[39min\u001b[39;00m attributes:  \u001b[39m#for each feature in the dataset\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     feature_info_gain \u001b[39m=\u001b[39m calculate_info_gain(attribute, data, class_list, purity_measurement)\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m max_info_gain \u001b[39m<\u001b[39m feature_info_gain: \u001b[39m#selecting feature name with highest information gain\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         max_info_gain \u001b[39m=\u001b[39m feature_info_gain\n",
      "File \u001b[1;32mc:\\Users\\u1462352\\OneDrive - University of Utah\\Desktop\\git\\utah-machine-learning\\Ensemble Learning\\DecisionTree.py:57\u001b[0m, in \u001b[0;36mcalculate_info_gain\u001b[1;34m(feature_name, data, class_list, purity_measurement)\u001b[0m\n\u001b[0;32m     54\u001b[0m feature_info \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m feature_value \u001b[39min\u001b[39;00m feature_value_list:\n\u001b[1;32m---> 57\u001b[0m     feature_value_data \u001b[39m=\u001b[39m data[data[feature_name] \u001b[39m==\u001b[39;49m feature_value] \u001b[39m#filtering rows with that feature_value\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     feature_value_count \u001b[39m=\u001b[39m feature_value_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m purity_measurement \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3887\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3885\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3886\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3887\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[0;32m   3889\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3890\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3891\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3949\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   3948\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 3949\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4077\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m, indices, axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[0;32m   4079\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4081\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4086\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4087\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4088\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   4089\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4090\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4063\u001b[0m     \u001b[39m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4064\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\n\u001b[0;32m   4065\u001b[0m         indices\u001b[39m.\u001b[39mstart, indices\u001b[39m.\u001b[39mstop, indices\u001b[39m.\u001b[39mstep, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp\n\u001b[0;32m   4066\u001b[0m     )\n\u001b[1;32m-> 4068\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[0;32m   4069\u001b[0m     indices,\n\u001b[0;32m   4070\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[0;32m   4071\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   4072\u001b[0m )\n\u001b[0;32m   4073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39m__finalize__(\n\u001b[0;32m   4074\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4075\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:877\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    874\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[0;32m    876\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 877\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[0;32m    878\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[0;32m    879\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[0;32m    880\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    881\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    882\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    883\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:670\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    663\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    664\u001b[0m         indexer,\n\u001b[0;32m    665\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[0;32m    666\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[0;32m    667\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m    671\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m    672\u001b[0m             indexer,\n\u001b[0;32m    673\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    674\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n\u001b[0;32m    675\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n\u001b[0;32m    676\u001b[0m             ),\n\u001b[0;32m    677\u001b[0m         )\n\u001b[0;32m    678\u001b[0m         \u001b[39mfor\u001b[39;49;00m blk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks\n\u001b[0;32m    679\u001b[0m     ]\n\u001b[0;32m    681\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m    682\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:671\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    663\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    664\u001b[0m         indexer,\n\u001b[0;32m    665\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[0;32m    666\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[0;32m    667\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 671\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m    672\u001b[0m             indexer,\n\u001b[0;32m    673\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    674\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n\u001b[0;32m    675\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n\u001b[0;32m    676\u001b[0m             ),\n\u001b[0;32m    677\u001b[0m         )\n\u001b[0;32m    678\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m    679\u001b[0m     ]\n\u001b[0;32m    681\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m    682\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:1061\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m   1062\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[0;32m   1063\u001b[0m )\n\u001b[0;32m   1065\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[39m#  these assertions\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1068\u001b[0m     \u001b[39m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     \u001b[39m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\array_algos\\take.py:118\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[0;32m    117\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import calculate_error_rate\n",
    "training_errors = []\n",
    "testing_errors = []\n",
    "\n",
    "for n in range(1, 11):  # Looping n from 1 to 500\n",
    "    bagged_model = BaggedTrees(n_trees=n)\n",
    "    bagged_model.fit(train_data, attributes)\n",
    "\n",
    "    # Training error\n",
    "    predictions = bagged_model.predict(train_data)\n",
    "    true_labels_train = train_data.iloc[:, -1].tolist()\n",
    "    error_rate_train = calculate_error_rate(predictions, true_labels_train)\n",
    "    training_errors.append(error_rate_train)\n",
    "\n",
    "    # Testing error\n",
    "    predictions = bagged_model.predict(test_data)\n",
    "    true_labels_test = test_data.iloc[:, -1].tolist()\n",
    "    error_rate_test = calculate_error_rate(predictions, true_labels_test)\n",
    "    testing_errors.append(error_rate_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), training_errors, label='Training Error', marker='o')\n",
    "plt.plot(range(1, 11), testing_errors, label='Testing Error', marker='x')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('Error Rates vs. Number of Trees')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
